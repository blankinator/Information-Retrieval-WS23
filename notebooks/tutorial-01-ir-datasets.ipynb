{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR Lab WiSe 2023: Topics, Documents, and Relevance Judgments\n",
    "\n",
    "Information retrieval experiments follow the [Cranfield Paradigm](https://en.wikipedia.org/wiki/Cranfield_experiments) that states that retrieval systems are evaluated using a set of information needs (topics), documents, and relevance judgments.\n",
    "\n",
    "We will use the [ir_datasets](https://ir-datasets.com/) and [tira](https://www.tira.io/task-overview/ir-lab-jena-leipzig-sose-2023) libraries to look at some examples using the retrieval scenario of the [IR Anthology](https://ir.webis.de/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation: Install dependencies\n",
    "\n",
    "First, we install the libraries `tira` and `ir_datasets`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is only needed in Google Colab, in a dev container, everything should be installed already\n",
    "# !pip3 install tira ir_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the dataset and imports\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tira.third_party_integrations import ir_datasets\n",
    "\n",
    "dataset = ir_datasets.load('ir-lab-jena-leipzig-sose-2023/iranthology-20230618-training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: View first Five Topics\n",
    "\n",
    "The `dataset.queries_iter()` method creates an iterable over all topics in the dataset.\n",
    "Each topic has an `query_id`, the string that is submitted to the search engine as query (can be accessed via `default_text`), a `description` that specifies what searchers with this information need are looking for, and a `narrative` that specifies which documents are relevant and which documents are non-relevant.\n",
    "\n",
    "E.g., Topic `3` tries to identify papers that `help to recognize signs of self-harm in people's social media posts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for query in list(dataset.queries_iter())[:3]:\n",
    "    print('\\nQuery: ', query.query_id)\n",
    "    print('\\tText:\\t\\t' + query.default_text())\n",
    "    print('\\tDescrition:\\t' + query.description)\n",
    "    print('\\tNarrative:\\t' + query.narrative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: View First Five Relevance Judgments\n",
    "\n",
    "The `dataset.qrels_iter()` method creates an iterable over all relevance judgments (qrels for query relevance) of the dataset.\n",
    "Each qrel entry consists of an `query_id` pointing to an topic, an `doc_id` pointing to a document, and a relevance label indicating if a document is relevant (relevance > 0) or not relevant (relevance is 0) to a query. The iteration field is \"historically unused\".\n",
    "\n",
    "E.g., the first line below indicates that document `2005.ipm_journal-ir0anthology0volumeA41A1.7` is relevant to the query `retrieval system improving effectiveness`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qrel in list(dataset.qrels_iter())[:5]:\n",
    "    # Access via: qrel.query_id, qrel.doc_id, qrel.relevance\n",
    "    print(qrel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Access to documents\n",
    "\n",
    "The `dataset.docs_store()` method provides random access via the document ID to all documents of a corpus.\n",
    "\n",
    "For instance, `docs_store.get('2005.ipm_journal-ir0anthology0volumeA41A1.7')` returns the document with id `2005.ipm_journal-ir0anthology0volumeA41A1.7` that has the text `\"A probabilistic model for ... linguistic knowledge.\"`.\n",
    "\n",
    "The `dataset.docs_iter()` method creates an iterable over all documents in a corpus (can be suitable to build an index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The dataset has', len(list(dataset.docs_iter())), 'documents.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_store = dataset.docs_store()\n",
    "\n",
    "docs_store.get('2005.ipm_journal-ir0anthology0volumeA41A1.7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Create some Descriptive Statistics for the Relevance Judgments\n",
    "\n",
    "Next, we want to create a [Pandas DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) that shows the proportion of relevant documents per topic.\n",
    "You can imagine a DataFrame as a table.\n",
    "\n",
    "First, we show how to use the pandas DataFrame API, second, it is on you to create this table using the real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {'query_id': 'test-1', 'query': 'some test query 1', 'proportion_relevant': 0.3},\n",
    "    {'query_id': 'test-2', 'query': 'some test query 2', 'proportion_relevant': 0.4},\n",
    "    {'query_id': 'test-3', 'query': 'some test query 3', 'proportion_relevant': 0.2},\n",
    "])\n",
    "\n",
    "df.sort_values('proportion_relevant', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E.g., in the hypothetical example above, the query `test-2` has the highest proportion of relevant documents.\n",
    "\n",
    "Next, please create a pandas DataFrame `df` containing that reports the proportion of relevant documents per topic on the real data, using `dataset.queries_iter()` and `dataset.qrels_iter()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proportion_relevant(topic_num):\n",
    "    rel, non_rel = 0, 0\n",
    "    for qrel in dataset.qrels_iter():\n",
    "        if qrel.query_id == str(topic_num):\n",
    "            rel += 1 if qrel.relevance else 0\n",
    "            non_rel += 0 if qrel.relevance else 1\n",
    "    return rel / (rel + non_rel)\n",
    "\n",
    "df = []\n",
    "for query in dataset.queries_iter():\n",
    "    df += [{'qid': query.query_id, 'query': query.title, 'Proportion Relevant': proportion_relevant(query.query_id)}]\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "df.sort_values('Proportion Relevant')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Find Difficult Topics\n",
    "\n",
    "Identify the query with the lowest proportion of relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Find Easy Topics\n",
    "\n",
    "Identify the query with the highest proportion of relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Find a Topic that is not Suitable to Distinguish Retrieval Systems\n",
    "\n",
    "The goal of retrieval experiments is to seperate effective retrieval systems from ineffective retrieval systems.\n",
    "Have you an idea what topics in the dataset are not well suited to distinguish effective from ineffective systems?\n",
    "\n",
    "Please select a single topic, and describe why it is not suited to distinguish retrieval systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Find a Topic that useful to Distinguish Retrieval Systems\n",
    "\n",
    "The goal of retrieval experiments is to seperate effective retrieval systems from ineffective retrieval systems.\n",
    "In step 8, you identified a topic that barely can distinguish effective from ineffective retrieval systems.\n",
    "\n",
    "Now, please identify a single topic that is better suited for separating retrieval systems and explain why the topic is better suited. How did you select your topic, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
